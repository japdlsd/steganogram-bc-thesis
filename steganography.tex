\chapter{Image-based steganography}

In this chapter we will cover the term steganography and explain 
how can we measure its strength. Then we will proceed to image-based
(specifically to JPEG-based) steganography. We will end this chapter
with overview of present state in free and/or open-source software
for steganography on Android platform.

\section{What steganography is?}

Steganography is an art of hiding information. The difference between steganography and
cryptography is that the goal of cryptography is to hide the content of message, whereas
the goal of steganography is to conceal the very fact that the message exists.

\subsubsection{A bit of terminology}

Information, which we want to hide, is often called \textit{secret message}. The object,
in which we want to embed our secret message, is often called \textit{cover message} (or, in our case,
\textit{cover image}). Additional information, required to detect and extract the secret message
from cover object, is called \textit{stegokey} (as opposed to cryptokey, which is used to 
unveil the content of the message). If the stegokey, needed to embed a message is different
from the key, needed to extract it, we call this steganographic method \textit{asymmetric}. In
other case, we call it \textit{symmetric}.

\section{How to measure strength of steganographic methods?}

Basic idea is simple: if a message concealed by method X was not discovered, then it's a good method.
But the concealing power depends on the message length (example: it is relatively easy
to write one date on your schooldesk without having your professor seeing it, but it's a lot
harder to write a whole textbook on it). 

Keeping that in mind, one can never tell with $100\%$
guarantee that this object doesn't carry any message, as sometimes it could carry only one bit 
(e.g. wearing the hat; having newspaper in your left hand; sending a postcard; etc.).

So instead another method is often used: whether the attacker can predict (or rather guess) the
length of embedded message.

\TODO some concrete stuff about measuring the strength

\section{Image-based steganography}
\label{sec:image-steganography}

How to hide messages in lossless image formats and why it isn't a good idea.

\TODO lossless images stego and discussion about suitability

\section{JPEG compression algorithm}
\label{sec:jpeg}

JPEG format provides many options for storing images. We will talk about
one of the most common versions. For further details we recommend to read \TODO source.

Input of compression algorithm is a raw image with pixels encoded
in RGB model (each pixel is encoded as three 8-bit numbers, representing
red, green and blue component of resulting colour, resluting in 24 bits of information
per pixel).

Compression consists of several steps:
\begin{enumerate}
    \item Transformation from RGB to YCbCr color space
    \item Reduction of Cb and Cr channels definition (lossy operation)
    \item Splitting each channel into $8 \times 8$ bytes long blocks 
    \item Discrete cosine transformation (DCT) of numbers in each block
    \item Rounding of DCT coefficients (main lossy operation)
    \item (Lossless) compression of coefficients (main compression operation)
\end{enumerate}

\subsubsection{Color space transformation}

Pixels are transformed from RGB to YCbCr color space. Y channel represents
brightness of a pixel ({which can be viewed as greyscale copy of the original image}),
Cb and Cr components represent so called \textit{chrominance} -- color without brightness. 
You can see example in figure \ref{img:YCbCr}.


%(based on source: \url{https://en.wikipedia.org/wiki/File:Barns_grand_tetons_YCbCr_separation.jpg})
\begin{figure}
%vlozenie samotneho obrazku vycentrovaneho a vhodnej velkosti
%obrazok je v subore images/cervik.png
\centerline{\includegraphics[height=0.4\textheight]{images/Barns_grand_tetons_YCbCr_separation_quad.jpg}}
%popis obrazku
\caption[Example of YCbCr color space (Public domain)]{Example of YCbCr color space. 
Left upper corner is an original image,
right upper corner --- Y channel (grayscale version of image),
left lower --- Cb channel,
right lower --- Cr channel.}
%id obrazku, pomocou ktoreho sa budeme na obrazok odvolavat
\label{img:YCbCr}
\end{figure}

\subsubsection{Downsampling}

Human eye is more sensitive to small changes of brightness rather 
than small changes in the hue and color saturation. Using that fact, 
we can use less space to represent Cr and Cb channels with almost no visible change
to an image. 

There are many options, but one of the most used is to use 4 bits instead of 8
to represent Cr and Cb and 8 bits to represent Y channel (so Y channel is left unchanged).

\subsubsection{Splitting into blocks}

Each channel is divided into $8 \times 8$ bytes long blocks and 
then processed separately. If channel is not exact multiple of block size,
then incomplete blocks are filled with fake values (there are several
methods to construct them, but details are irrelevant for our purposes. 
For further information, you may read \TODO source).

\subsubsection{Discrete cosine transformation}

\begin{comment}
Each block could be seen as finite integer sequence.
This sequence can be seen as values of some function $f$ 
in predefined points $x_1$, $x_2$, \ldots, $x_{64}$.

Discrete cosine transformation is a way of representing this
function as a linear combination of sinusoids (so called \textit{basis functions}) 
based on values of $f(x_1)$, $f(x_2)$, \ldots, $f(x_{64})$. Coefficients of this
linear combinations are called \textit{the DCT coefficients} and
are stored instead of original values, because the original 
values can be later evaluated from them. Figure \ref{img:DCTbf} shows the basis functions.

\end{comment}

Dicsrete cosine transformation is a way of representing block of pixels as 
a linear combination of so called \textit{basis functions}, showed on figure \ref{img:DCTbf},
so we can store coefficients of linear combination instead of the original values.

% source: \url{https://en.wikipedia.org/wiki/File:Dctjpeg.png}
\begin{figure}
%vlozenie samotneho obrazku vycentrovaneho a vhodnej velkosti
%obrazok je v subore images/cervik.png
\centerline{\includegraphics[width=0.5\textwidth]{images/Dctjpeg.png}}
%popis obrazku
\caption[DCT basis functions (Public domain)]{DCT basis functions.}
%id obrazku, pomocou ktoreho sa budeme na obrazok odvolavat
\label{img:DCTbf}
\end{figure}



\subsubsection{Rounding of DCT coefficients}

Here we use two facts. First, DCT basis functions varies from simple
to very complex. Second, human eye is less capable to distinguish such
fine local changes. Therefore, we can represent coefficients of complex
basis functions with less definition (in other words, quantize them).

The level of quantization is defined by demanded quality ratio.

The most fine quailty $Q=100\%$ let all coefficients be rounded to whole numbers,
so it still would be lossy operation.

\subsubsection{Lossless compression of DCT coefficients}

Another interesting property of DCT is that the coefficients
of last basis functions are often very small (because DCT "tries"
to express image with the first sinusoids). Therefore, after
quantisation process many of DCT coefficients could be zero.

The coefficients in each block are ordered in so called \emph{zigzag}
order (by the diagonals from the left upper corner of the block) and
then encoded by Huffman encoding \TODO the ending.

\TODO add an image of the zigzag order


As could be expected, long sequences of zeros could be efficiently
compressed, and therefore significant compress ratio could be achieved.


\section{How to hide information in JPEG?}
\label{sec:how-to-hide-information}

\textit{This section is based on article \cite{liu2008high}.}


An image encoded in JPEG format could be seen as a bunch of (quantized)
DCT coefficients, which are just regular integer numbers. One of the
most natural ideas is to change least significant bits (LSB) of these
numbers to store our message, as these changes are mostly invisible
for human eye and the message can be extracted without knowledge of
the original image.

Problems with direct application of this method is that coefficients with values
$0$ or $1$ would be changed drastically and it would create great disproportion
in amount of zeros and ones.

Modern algorithms try to fight with statistical approach by devising ways to
keep intact various statistical properties of resulting numbers. 

\subsection{JSteg library (direct LSB)}

This library embed secret message in least significant bits of DCT coefficients sequentially.

This approach was quite common for a period of time (there were even algorithms that performed such embedding
in lossless images), but in year 1999 Westfeld and Pfitzmann came up with a so called \textit{chi-square attack}.

\subsection{Chi-square attack}

As you can see in the original paper \cite{westfeld1999attacks}, 
this attack was initially pointed against algorithms with lossless cover images, 
but this approach can be applied for JPEG images too.

Westfeld and Pfitzmann pointed out, that relative amount of values of the DCT coefficients (or pixels in the original paper), 
which differ only in their LSB (so called \textit{paired values}, or \textit{PoV}), is mostly very far from equal 
(i.e. there it is more probable that there would be $1000$ coefficients with value $30$ and $4000$ coefficients with value $31$
than that there would $2500$ of each).

Assuming that 0 and 1 bits are distributed uniformly in the secret message 
(which is usually the case for compressed and/or encrypted message), relative
amount of PoVs becomes equal. And assuming sequential writing in DCT coefficients, one can test
whether paired values show such behaviour. The corresponding statistics has chi-square
distribution, from which this attack got its name.

Let there be $M$ different PoV in the image (e.g. one pair could be $20$-$21$). Let $N_{k, 0}$ ($k \in \{ 1, \ldots, M\}$)
denote the amount of coefficients of $k$-th PoV with $0$ in the least significant bit. Analogically,
$N_{k, 1}$ would denote the amount of coefficients with $1$ in the least significant bit. 
Let denote $N_k := N_{k, 0} + N_{k, 1}$. It is important that the LSB steganography does not change
any of $N_k$.
 
Let our null hypothesis be that an encrypted message (with uniform distribution of $0$ and $1$) 
was embedded into these coefficients (and alternative 
hypothesis would be the opposite sentence). Assuming the null hypothesis, we can see $N_{k, 0}$ as a random
variable following binomical distribution with $n = N_k$ and $p = \frac{1}{2}$, i.e.
$$N_{k, 0} \sim Bin\left(N_k, \frac{1}{2}\right)$$
This distribution can be approximated with normal distribution, i.e.
$$N_{k, 0} \overset{\cdot}{\sim} N\left(\frac{N_k}{2}, \frac{N_k}{4}\right)$$
We can then normalize that variable to $N(0, 1)$ distribution, i.e.
$$ \tilde{N}_{k, 0} := \frac{N_{k, 0} - \frac{N_k}{2}}{\sqrt{\frac{N_k}{4}}}  \overset{\cdot}{\sim} N( 0, 1)$$

Then the sum of squares of such random variables $\tilde{N}_{k, 0}$ would approxiamtely follow the $\chi^2$ distribution with $M-1$
degrees of freedom (we subract one because the sum of all variables is fixed), i.e.
$$\sum_{k = 1}^{M} \tilde{N}^{2}_{k, 0} \overset{\cdot}{\sim} \chi^2_{M-1}$$

We can simplify the expression a bit to get the final statistics: 
$$\sum_{k = 1}^{M} \tilde{N}^{2}_{k, 0} = 
\sum_{k = 1}^{M} \left(  \frac{N_{k, 0} - \frac{N_k}{2}}{\sqrt{\frac{N_k}{4}}}  \right)^2 =
\sum_{k = 1}^{M} \frac{\left(N_{k, 0} - \frac{N_k}{2}\right)^2}{\frac{N_k}{4}} = 
\sum_{k = 1}^{M} \frac{\left(2 N_{k, 0} - N_k\right)^2}{N_k}
=: T
$$ 

Now we can construct a test for our hypothesis. We can do it, for example, by evaluating
the $(1 - \alpha)\%$ confidence interval ($\alpha$ is usually chosen as $5\%$) for $\chi^2$ distribution, which is equal to 
$\left( \chi^2_{M-1}\left(\frac{\alpha}{2}\right), \chi^2_{M-1}\left(1 - \frac{\alpha}{2}\right) \right)$, where $\chi^2_{M-1}(x)$ 
is a $x$-th quantile of this distribution.
(e.g. for $\alpha = 5\%$
and $M=100$ this interval is equal to $(73.36108, 128.422)$). 

The test then work in following way: if evaluated $T$ statistics is 
out of the confidence interval, then the null hypothesis is rejected, i.e. it is unprobable that there is a hidden message. 

This attack could be extended to random writing (i.e. that DCT coefficients to be used
are chosen randomly) by using shifting windows, so we can speak about \textit{extended chi-square attack}. 
This approach is decribed in the paper \cite{provos2001detecting}.

\subsection{F5 algorithm}

In order to defend against chi-square attack, Westfield and Pfitzmann proposed to use 
subtraction operation to match the secret bit inspite of the replacing the last bit. In this way,
the PoVs (decribed in previous subsection) won't be so drastically changed. This approach was applied
in Westfeld's algorithm F5 (decribed in paper \cite{steganalysis2001f5}).

The algorithm is a bit complex, and so it is originally describe as a series of algorithms (thus the number $5$)
with gradual removal of the flaws.

F3 algorithm decreases the absolute value of the coefficients to match the secret bits inspite of their replacement, 
thus being resistant against chi-square attack. Because of this approach, it skips zero coefficients. The problem is
that if the original coefficient has the absolute value $1$ and the secret bit is $0$, then after the embedding
the coefficient would be $0$. The receiver cannot distinguish between unused and decremented zeros, so algorithm
has to embed this bit in the next coefficient available.

This approach leads to two problems: F3 created more zeros than ones in the LSB of coefficients, creating the peculiar
statistically detectable histogram, and that the original JPEG coefficients contain more odd than even values, and so
the \emph{unchanged} part of a message contains more ones than zeros in LSBs.

F4 solves these problems by inverting the meaning of negative coefficients, so that odd negative coefficient means $0$
and even negative means $1$.

F4 and F3 both suffer from sequential using of the DCT coefficients. F5 removes this weakness by choosing the coefficients
in a random way (based on a stegonagraphic key). Additionally, F5 uses so called \emph{matrix encoding} to increase effectiveness
of embedding ratio.

F5 algorithm is currently used in many steganographic Android apps, mainly because of its open Java implementation. However, this
algorithm can be successfully attacked with so called \emph{S attack}.


\subsection{S attack}

This attack is based on further compression of cover image and comparing 
specifically constructed statistics $S$ of the original and compressed images.

\TODO detailed description

\subsection{Complementary embedding algorithm (CE)}

This algorithms was designed to be resistant against both S and chi-square attacks families.

Because it's the algorithm we had used in our application, 
we've decided to put the description of this algorithm in chapter \ref{chap:theory}
along with the decsriptions of other used algorithms (you can find it in the subsection
\ref{ssec:ce}).

\subsection{Bernford law}

\TODO 

\TODO add Pm1 using genetic algorithms

\TODO add SVM and general machine learning for steganalysis

\section{Present state of free and/or open-source programs}

\TODO show general mistakes: fixed stegokeys, closed implementation, hardness of usage of correct crypto
